% !TeX root = ../main.tex
% -*- coding: utf-8 -*-

\chapter{总结与展望}

论文提出了能够解决多人博弈问题的“自适应 Deep Q-Learning 算法”。该方法将传统的理论强化学习方法与新兴的深度学习技术相结合，其创新点在于使用了双神经网络来抵消偏差，以及分离神经网络进行交互博弈，来进行自适应学习。

实验结果表明，该算法能够较好地解决不完全信息博弈问题，收敛速度快同时收敛效果好，且该算法短时间内能进行大量级的数据训练，算法效率高。但同时也有着明显的提升空间，有待进一步地加深研究。

随着机器学习理论的不断发展，其在实际中的应用也渐渐受到重视。传统的针对数据集内部关系问题的监督学习和无监督学习已经得到了广泛的研究，而新兴的实时反馈数据型博弈问题则渐渐成为一个关注的重点，这使得强化学习在机器学习中变得越发重要。

目前，对于简单的完全信息博弈问题，已经提出了许多有着不错成果的强化学习理论，如结合了 Monte Carlo 树搜索的 AlphaGo 算法\cite{silver2017mastering}，但对于更实际且更复杂的不完全信息博弈问题，还尚未得到充分的研究，因此，针对不完全信息博弈问题的强化学习将会是未来的一个重要研究方向，有待进一步地充分研究。