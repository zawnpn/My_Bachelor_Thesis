% !TeX root = ../main.tex
% -*- coding: utf-8 -*-


\begin{zhaiyao}

传统的强化学习由于理论上的各种假设与限制，只适用于简单的“完全信息博弈问题”，为了能够解决实际中更常见但也更复杂的“不完全信息博弈问题”，本文首先基于模拟采样的思路对传统的理论算法进行改进，解决了不完全信息下难以建模的根本问题。又基于统计学中的 Bootstrap 思想，将模拟采样与 Bootstrap 估计值相结合，改善数据的使用效率，提升模拟近似的准确性。最后再与梯度下降法和深度神经网络相结合，进一步提升算法的运算效率，提出了针对多人不完全信息博弈的“自适应 Deep Q-Learning 算法”。实验表明，“自适应 Deep Q-Learning 算法”能够通过强化学习有效探索出多人博弈技巧，且时间复杂度也表明该算法能够高效快速处理较大数量级的数据集。

\end{zhaiyao}


\begin{guanjianci}
强化学习；不完全信息博弈；模拟采样；神经网络；自适应
\end{guanjianci}



\begin{abstract}


This is the abstract.

\end{abstract}



\begin{keywords}
Thesis; template
\end{keywords}